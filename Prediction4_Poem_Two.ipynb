{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prediction4 Poem Two.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlsSZ4fGCliHB6bTrYUIgR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YazCodes/Deep-Learning-projects/blob/main/Prediction4_Poem_Two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkDZpvp4JcIl"
      },
      "source": [
        "# import python libraries\n",
        "import numpy as np\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from random import randint\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHZ4dAgUJrBi",
        "outputId": "4193078d-c842-494e-91ab-926df1a67f52"
      },
      "source": [
        "import nltk   # natural language tool kit library\n",
        "nltk.download('gutenberg')  # downloads a library that NLTK uses\n",
        "\n",
        "from nltk.corpus import gutenberg as gut  # downloads the gutenberg dataset\n",
        "print(gut.fileids())    # prints the name of the files in the dataset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mky1xpRZJvRr"
      },
      "source": [
        "# get the book text\n",
        "book_text = nltk.corpus.gutenberg.raw('blake-poems.txt')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1HluAH6J7S2",
        "outputId": "de6834b5-dcb4-4bbb-b5bc-fbd74141728d"
      },
      "source": [
        "# print the first 500 characters of the text so we can look at it\n",
        "print(book_text[:500])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Poems by William Blake 1789]\n",
            "\n",
            " \n",
            "SONGS OF INNOCENCE AND OF EXPERIENCE\n",
            "and THE BOOK of THEL\n",
            "\n",
            "\n",
            " SONGS OF INNOCENCE\n",
            " \n",
            " \n",
            " INTRODUCTION\n",
            " \n",
            " Piping down the valleys wild,\n",
            "   Piping songs of pleasant glee,\n",
            " On a cloud I saw a child,\n",
            "   And he laughing said to me:\n",
            " \n",
            " \"Pipe a song about a Lamb!\"\n",
            "   So I piped with merry cheer.\n",
            " \"Piper, pipe that song again;\"\n",
            "   So I piped: he wept to hear.\n",
            " \n",
            " \"Drop thy pipe, thy happy pipe;\n",
            "   Sing thy songs of happy cheer:!\"\n",
            " So I sang the same again,\n",
            "   While he wept wi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-E0bJuMPViS"
      },
      "source": [
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgOQUbvOJ--v"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence.lower()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "rEUJM4ZMKJis",
        "outputId": "e617f44f-8a05-42f5-9ea6-1c5eedde7c37"
      },
      "source": [
        "book_text = preprocess_text(book_text)\n",
        "book_text[:500]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' poems by william blake songs of innocence and of experience and the book of thel songs of innocence introduction piping down the valleys wild piping songs of pleasant glee on cloud saw child and he laughing said to me pipe song about lamb so piped with merry cheer piper pipe that song again so piped he wept to hear drop thy pipe thy happy pipe sing thy songs of happy cheer so sang the same again while he wept with joy to hear piper sit thee down and write in book that all may read so he vanish '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkYZmSV2Ko4Q",
        "outputId": "d453b55f-734c-46fd-ba3e-8b4c4a6ef88c"
      },
      "source": [
        "# increasing the amount of data from 20000 to 30000\n",
        "print(len(book_text))\n",
        "book_text = book_text[:30000]\n",
        "print(len(book_text))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34028\n",
            "30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiv42qx_PQbT"
      },
      "source": [
        "Conveting the words to  numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDiBtJvWPZWP",
        "outputId": "af60c29f-c543-41fd-b110-895233c0cb93"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "# punkt is a sentence tokenizer that nltk requires. \n",
        "# It divides a text into a list of sentences, by using an unsupervised algorithm \n",
        "# to build a model for abbreviation words, collocations, and words that start sentences\n",
        "nltk.download('punkt')\n",
        "\n",
        "book_text_words = (word_tokenize(book_text))\n",
        "n_words = len(book_text_words)\n",
        "unique_words = len(set(book_text_words))\n",
        "\n",
        "print('Total Words: %d' % n_words)\n",
        "print('Unique Words: %d' % unique_words)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Total Words: 5811\n",
            "Unique Words: 1381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qiB0JSZPd1S"
      },
      "source": [
        "# convert words to numbers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=900)\n",
        "tokenizer.fit_on_texts(book_text_words)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4GaYsnePmu7"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1    # word_index is the dictionary. Store the number of unique words in vocab_size variable\n",
        "word_2_index = tokenizer.word_index           # store the dictionary in the variable called word_2_index"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiQBIQuxQurR",
        "outputId": "9de9e72c-8298-44fe-a56f-23e4c6e6604d"
      },
      "source": [
        "#print the 500th word in the dictionary and it's index - the word kissed is now a number 247!\n",
        "print(book_text_words[500])\n",
        "print(word_2_index[book_text_words[500]])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kissed\n",
            "329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L78244AQQ5ac"
      },
      "source": [
        "creating input sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ0-zMLHQ8Bv"
      },
      "source": [
        "input_sequence_words = []  # input sequences in words (used for metric evaluation later on)\n",
        "input_sequence = []   # empty list to hold the sequences that will be input into our model\n",
        "output_words = []     # empty list to hold the output words\n",
        "input_seq_length = 25  # length of the input sequence\n",
        "\n",
        "# form the input sequence list and the output words list\n",
        "for i in range(0, n_words - input_seq_length , 1):\n",
        "    in_seq = book_text_words[i:i + input_seq_length]\n",
        "    input_sequence_words.append(in_seq)\n",
        "    out_seq = book_text_words[i + input_seq_length]\n",
        "    input_sequence.append([word_2_index[word] for word in in_seq])\n",
        "    output_words.append(word_2_index[out_seq])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4SmqXLEROVq",
        "outputId": "a35f75c9-2db6-4daf-9719-e368b6545da2"
      },
      "source": [
        "# print the first sequence to see what it looks like - a list of 100 integers that represent the first observation of words\n",
        "print(len(input_sequence))      # print the number of input sequences\n",
        "print(input_sequence[0])        # print the first input sequence\n",
        "print(len(input_sequence[0]))   # print the length of the first input sequence"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5786\n",
            "[644, 35, 417, 251, 145, 4, 309, 2, 4, 310, 2, 1, 169, 4, 76, 145, 4, 309, 418, 311, 55, 1, 312, 108, 311]\n",
            "25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-iX80LnRYE9"
      },
      "source": [
        "# reshape the input sequences to be 3-dimensional\n",
        "# X = np.reshape(input_sequence, (3562, 100, 1))    # number of input sequences, length of each sequence\n",
        "X = np.reshape(input_sequence, (len(input_sequence), input_seq_length, 1))\n",
        "\n",
        "# Normalize the data by dividing by the max number of unique words (the vocab size)\n",
        "X = X / float(vocab_size)\n",
        "\n",
        "# one-hot encode the output words so that they can be used by the model (converts the output to 2-dimensions)\n",
        "y = to_categorical(output_words)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08l7pbj7RaLj",
        "outputId": "1ff200f2-ceef-43f5-c2db-9622efd25a1f"
      },
      "source": [
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (6565, 25, 1)\n",
            "y shape: (6565, 1506)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uZRHvhgRk6X"
      },
      "source": [
        "Create, compile and fit the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPQn9kykRkLQ",
        "outputId": "4477b141-010a-40a9-db36-9a504b998678"
      },
      "source": [
        "model = Sequential()\n",
        "# LSTM layer has 800 neurons (units).  The input shape is (100, 1) (Number of words in a sequence, 1 to make it 2D data) (Number of time-steps, features per time-step)\n",
        "model.add(LSTM(900, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "\n",
        "model.add(LSTM(900, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(900, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(900))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# the output word can be one of any of the unique words in the vocabulary\n",
        "# This means it is a multi-class calssification problem and we use the categorical crossentropy loss function\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_9 (LSTM)                (None, 25, 900)           3247200   \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 25, 900)           6483600   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 25, 900)           0         \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 25, 900)           6483600   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 25, 900)           0         \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 900)               6483600   \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 900)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1382)              1245182   \n",
            "=================================================================\n",
            "Total params: 23,943,182\n",
            "Trainable params: 23,943,182\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5vfiU1RRsi-",
        "outputId": "364f5a44-39f4-4698-9f0e-96c3b6fcabff"
      },
      "source": [
        "model.fit(X, y, batch_size=32, epochs=5, verbose=1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "181/181 [==============================] - 787s 4s/step - loss: 6.5449\n",
            "Epoch 2/5\n",
            "181/181 [==============================] - 778s 4s/step - loss: 6.1646\n",
            "Epoch 3/5\n",
            "181/181 [==============================] - 778s 4s/step - loss: 6.1413\n",
            "Epoch 4/5\n",
            "181/181 [==============================] - 778s 4s/step - loss: 6.0869\n",
            "Epoch 5/5\n",
            "181/181 [==============================] - 778s 4s/step - loss: 6.1058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d386227d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXmrea_JTi_i"
      },
      "source": [
        "Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBez5TlUTmwa",
        "outputId": "0df9b515-32a8-433c-f700-8c0eb54ae17d"
      },
      "source": [
        "# randomly select a sequence of integers from the input sequences\n",
        "random_seq_index = np.random.randint(0, len(input_sequence)-1)\n",
        "random_seq = input_sequence[random_seq_index]\n",
        "\n",
        "# convert the integer sequence to its words\n",
        "# word_2_index contains a dictionary of the format word : index (word being the key and index being the value)\n",
        "# the next line of code reverses this to index: word (index now being the key and word is now the value)\n",
        "# this reversed dictionary can now be used by supplying an index to it, and the word will be returned\n",
        "index_2_word = dict(map(reversed, word_2_index.items())) # swaps keys with values\n",
        "# loop round using a list iteration to get the list of words that correspond to the integers in the randomly picked sequence\n",
        "word_sequence = [index_2_word[value] for value in random_seq]\n",
        "\n",
        "# join the words in the list and print the sequence of words\n",
        "print(' '.join(word_sequence))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nor poverty the mind appall the little girl lost in futurity prophetic see that the earth from sleep grave the sentence deep shall arise and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrGw5lUMTxba"
      },
      "source": [
        "# this code predicts the next 25 words that follow the randomly picked sequence above\n",
        "# we loop round, making 25 predictions\n",
        "word_sequence = []\n",
        "for i in range(25):\n",
        "    int_sample = np.reshape(random_seq, (1, len(random_seq), 1))    # reshape to make 3-D input (1 sequence, length of the sequence, 1 because the first LSTM requires another dimension)\n",
        "    int_sample = int_sample / float(vocab_size)                     # normalise\n",
        "\n",
        "    predicted_word_index = model.predict(int_sample, verbose=0)     # predict\n",
        "\n",
        "    predicted_word_id = np.argmax(predicted_word_index)             # get the index of the maximum value (they are categorical so )\n",
        "\n",
        "    word_sequence.append(index_2_word[predicted_word_id])          # get the predicted word by finding the word at the predicted index\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRBEbPW_T5rc",
        "outputId": "8ecc73fc-be9d-4f81-a7a5-550f09decb81"
      },
      "source": [
        "# loop round the list of predicted words and print them out for our final prediction of the next 100 words\n",
        "final_output = \"\"\n",
        "for word in word_sequence:\n",
        "    final_output = final_output + \" \" + word\n",
        "\n",
        "print(final_output)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " the the the the the the the the the the the the the the the the the the the the the the the the the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLv1VF8MUFUj",
        "outputId": "47ee7b4e-e142-4298-e6de-56d0d5dbe36c"
      },
      "source": [
        "# Bleu score\n",
        "print(input_sequence_words[:2])       # print out the first 2 elements of the input sequence words list\n",
        "print(word_sequence)                  # print out the words of our randomly picked sequence\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "reference = input_sequence_words\n",
        "candidate = word_sequence\n",
        "\n",
        "score = sentence_bleu(reference, candidate)\n",
        "print(score)\n",
        "#Score = 0.727 \n",
        "# A perfect match results in a score of 1.0. The closet to 1 the better. "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['poems', 'by', 'william', 'blake', 'songs', 'of', 'innocence', 'and', 'of', 'experience', 'and', 'the', 'book', 'of', 'thel', 'songs', 'of', 'innocence', 'introduction', 'piping', 'down', 'the', 'valleys', 'wild', 'piping'], ['by', 'william', 'blake', 'songs', 'of', 'innocence', 'and', 'of', 'experience', 'and', 'the', 'book', 'of', 'thel', 'songs', 'of', 'innocence', 'introduction', 'piping', 'down', 'the', 'valleys', 'wild', 'piping', 'songs']]\n",
            "['the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']\n",
            "0.727427152512826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}