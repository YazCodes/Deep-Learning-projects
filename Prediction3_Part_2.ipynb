{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prediction3 Part 2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSvVj+msGZUUadlPWelu/R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YazCodes/Deep-Learning-projects/blob/main/Prediction3_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CUKWUcft3Hg"
      },
      "source": [
        "DQN for cartpole"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQNVaN0XtuNB",
        "outputId": "df4fbf4c-3070-49f3-a45c-1becdafe397a"
      },
      "source": [
        "# install keras rl2 (we need to install keras-rl2 so it works with the tensorflow 2 version that comes pre-installed with colab)\n",
        "!pip install keras-rl2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-rl2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/34/94ffeab44eef43e22a01d82aa0ca062a97392c2c2415ba8b210e72053285/keras_rl2-1.0.4-py3-none-any.whl (53kB)\n",
            "\r\u001b[K     |██████▏                         | 10kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 20kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 40kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (3.12.4)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (2.10.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (0.10.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.12)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (0.36.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (2.4.1)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow>=2.1.0->keras-rl2) (54.1.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (0.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (1.27.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (3.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (2020.12.5)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (4.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (0.4.8)\n",
            "Installing collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr6MBOzWuFJY",
        "outputId": "196e1d33-faf3-415d-9abe-54ca63056308"
      },
      "source": [
        "!pip install gym"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCP8mBGnuJ1E"
      },
      "source": [
        "# load the gym module\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "# import the usual Keras modules for creating deep neural networks\n",
        "from keras import Sequential\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "ENV_NAME = 'CartPole-v0'\n",
        "env = gym.make(ENV_NAME)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhQ1EbZLwhWD",
        "outputId": "36b2cf90-80ea-4cda-8073-d688fcc5cac6"
      },
      "source": [
        "print(env.observation_space.shape) #gives us a tupel. 0 is the first element of the tupel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUIQR1wtxnwL",
        "outputId": "2a7a65d4-44cf-4a08-faa8-beeaefa45504"
      },
      "source": [
        "#number of actions \n",
        "print(env.action_space.n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dEJwofrluTC2",
        "outputId": "65055926-0feb-4a3e-b98a-fffa21f34e1f"
      },
      "source": [
        "import rl\n",
        "from rl.memory import SequentialMemory  # import the exerience replay buffer module\n",
        "from rl.policy import BoltzmannQPolicy, LinearAnnealedPolicy, EpsGreedyQPolicy  # import the policy\n",
        "from rl.agents.dqn import DQNAgent      # import the DQN agent\n",
        "\n",
        "memory = SequentialMemory(limit=10000, window_length=1) #setting up the experince replay buffer\n",
        "#limit = the numer of steps of episodes stored in the replay buffer\n",
        "\n",
        "# define the policy (how we select the actions)\n",
        "# setup the Linear annealed policy with the EpsGreedyQPolicy as the inner policy\n",
        "policy =  LinearAnnealedPolicy(inner_policy=EpsGreedyQPolicy(),   # policy used to select actions\n",
        "                               attr='eps',                        # attribute in the inner policy to vary             \n",
        "                               value_max=1.,                       # maximum value of attribute that is varying\n",
        "                               value_min=.1,                      # minimum value of attribute that is varying\n",
        "                               value_test=.05,  #0.9??                  # test if the value selected is < 0.05\n",
        "                               nb_steps=9000)                    # the number of steps between value_max and value_min\n",
        "\n",
        "#need to change the value_max and value_min. \n",
        "# Q-Network\n",
        "model = Sequential() #sequnetial model \n",
        "model.add(Input(shape=(1,env.observation_space.shape[0]))) # 1 = one observation and env.observation_space.shape is the number of states within our observation. 0 = the first element of the tupel\n",
        "model.add(Flatten())\n",
        "# extra layers here\n",
        "model.add(Dense(32, activation='relu')) #layer 1\n",
        "model.add(Dense(64, activation='relu')) #layer 2\n",
        "#model.add(Dense(64, activation='relu')) #layer 2\n",
        "\n",
        "model.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space. Activation has to be linear due to how the q value does its calculation\n",
        "print(model.summary())\n",
        "\n",
        "# define the agent using the DQNAgent class\n",
        "dqn = DQNAgent(model=model,                     # Q-Network model created above ^\n",
        "               nb_actions=env.action_space.n,   # number of actions used above - the data from the enviroment\n",
        "               memory=memory,                   # experience replay memory\n",
        "               nb_steps_warmup=10,              # how many steps are waited before starting experience replay\n",
        "               target_model_update=1e-2,        # how often the target network is updated\n",
        "               policy=policy)                   # the action selection policy\n",
        "\n",
        "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=9000, visualize=False, verbose=2) #visualize false to save time\n",
        "\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "dqn.test(env, nb_episodes=20, visualize=False) #testing for 20 episodes, reward should all be 200- evaluating my algortithm \n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                160       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,402\n",
            "Trainable params: 2,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training for 9000 steps ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.7/dist-packages/rl/memory.py:40: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   39/9000: episode: 1, duration: 0.982s, episode steps:  39, steps per second:  40, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 0.399234, mae: 0.483572, mean_q: 0.117197, mean_eps: 0.997550\n",
            "   60/9000: episode: 2, duration: 0.156s, episode steps:  21, steps per second: 135, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 0.221424, mae: 0.506824, mean_q: 0.463249, mean_eps: 0.995100\n",
            "  112/9000: episode: 3, duration: 0.397s, episode steps:  52, steps per second: 131, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 0.057190, mae: 0.655638, mean_q: 1.110062, mean_eps: 0.991450\n",
            "  146/9000: episode: 4, duration: 0.256s, episode steps:  34, steps per second: 133, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.618 [0.000, 1.000],  loss: 0.019674, mae: 0.788883, mean_q: 1.496807, mean_eps: 0.987150\n",
            "  161/9000: episode: 5, duration: 0.116s, episode steps:  15, steps per second: 130, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.733 [0.000, 1.000],  loss: 0.021272, mae: 0.861217, mean_q: 1.661739, mean_eps: 0.984700\n",
            "  183/9000: episode: 6, duration: 0.186s, episode steps:  22, steps per second: 118, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 0.019896, mae: 0.931582, mean_q: 1.823222, mean_eps: 0.982850\n",
            "  193/9000: episode: 7, duration: 0.082s, episode steps:  10, steps per second: 122, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 0.019836, mae: 0.998287, mean_q: 1.982624, mean_eps: 0.981250\n",
            "  204/9000: episode: 8, duration: 0.097s, episode steps:  11, steps per second: 114, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 0.033949, mae: 1.040447, mean_q: 2.016626, mean_eps: 0.980200\n",
            "  217/9000: episode: 9, duration: 0.116s, episode steps:  13, steps per second: 112, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.154 [0.000, 1.000],  loss: 0.042815, mae: 1.095868, mean_q: 2.142764, mean_eps: 0.979000\n",
            "  231/9000: episode: 10, duration: 0.112s, episode steps:  14, steps per second: 125, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 0.051085, mae: 1.150853, mean_q: 2.271848, mean_eps: 0.977650\n",
            "  244/9000: episode: 11, duration: 0.109s, episode steps:  13, steps per second: 120, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 0.051486, mae: 1.200539, mean_q: 2.346135, mean_eps: 0.976300\n",
            "  269/9000: episode: 12, duration: 0.196s, episode steps:  25, steps per second: 128, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 0.065295, mae: 1.286392, mean_q: 2.514086, mean_eps: 0.974400\n",
            "  291/9000: episode: 13, duration: 0.174s, episode steps:  22, steps per second: 126, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 0.080504, mae: 1.398022, mean_q: 2.710211, mean_eps: 0.972050\n",
            "  307/9000: episode: 14, duration: 0.133s, episode steps:  16, steps per second: 121, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 0.099691, mae: 1.466535, mean_q: 2.762293, mean_eps: 0.970150\n",
            "  339/9000: episode: 15, duration: 0.256s, episode steps:  32, steps per second: 125, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.084907, mae: 1.564225, mean_q: 3.002408, mean_eps: 0.967750\n",
            "  364/9000: episode: 16, duration: 0.192s, episode steps:  25, steps per second: 131, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 0.104466, mae: 1.677699, mean_q: 3.236246, mean_eps: 0.964900\n",
            "  403/9000: episode: 17, duration: 0.292s, episode steps:  39, steps per second: 134, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 0.110221, mae: 1.809296, mean_q: 3.483780, mean_eps: 0.961700\n",
            "  423/9000: episode: 18, duration: 0.152s, episode steps:  20, steps per second: 131, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.171401, mae: 1.934780, mean_q: 3.649347, mean_eps: 0.958750\n",
            "  439/9000: episode: 19, duration: 0.147s, episode steps:  16, steps per second: 109, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 0.136420, mae: 2.002448, mean_q: 3.873619, mean_eps: 0.956950\n",
            "  464/9000: episode: 20, duration: 0.209s, episode steps:  25, steps per second: 119, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 0.146590, mae: 2.083675, mean_q: 3.996622, mean_eps: 0.954900\n",
            "  478/9000: episode: 21, duration: 0.115s, episode steps:  14, steps per second: 122, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 0.198997, mae: 2.141386, mean_q: 4.015840, mean_eps: 0.952950\n",
            "  502/9000: episode: 22, duration: 0.198s, episode steps:  24, steps per second: 121, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.139686, mae: 2.241373, mean_q: 4.305345, mean_eps: 0.951050\n",
            "  538/9000: episode: 23, duration: 0.287s, episode steps:  36, steps per second: 126, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 0.163620, mae: 2.369755, mean_q: 4.583610, mean_eps: 0.948050\n",
            "  559/9000: episode: 24, duration: 0.171s, episode steps:  21, steps per second: 123, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 0.156702, mae: 2.471812, mean_q: 4.768074, mean_eps: 0.945200\n",
            "  576/9000: episode: 25, duration: 0.147s, episode steps:  17, steps per second: 116, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 0.282570, mae: 2.562835, mean_q: 4.877582, mean_eps: 0.943300\n",
            "  600/9000: episode: 26, duration: 0.183s, episode steps:  24, steps per second: 131, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.206251, mae: 2.629499, mean_q: 5.055700, mean_eps: 0.941250\n",
            "  622/9000: episode: 27, duration: 0.169s, episode steps:  22, steps per second: 130, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.682 [0.000, 1.000],  loss: 0.263414, mae: 2.762826, mean_q: 5.280138, mean_eps: 0.938950\n",
            "  689/9000: episode: 28, duration: 0.476s, episode steps:  67, steps per second: 141, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 0.256914, mae: 2.914400, mean_q: 5.611160, mean_eps: 0.934500\n",
            "  746/9000: episode: 29, duration: 0.413s, episode steps:  57, steps per second: 138, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.561 [0.000, 1.000],  loss: 0.263981, mae: 3.152825, mean_q: 6.154887, mean_eps: 0.928300\n",
            "  759/9000: episode: 30, duration: 0.108s, episode steps:  13, steps per second: 120, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 0.216704, mae: 3.300801, mean_q: 6.470261, mean_eps: 0.924800\n",
            "  776/9000: episode: 31, duration: 0.148s, episode steps:  17, steps per second: 115, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 0.362400, mae: 3.347451, mean_q: 6.471475, mean_eps: 0.923300\n",
            "  787/9000: episode: 32, duration: 0.092s, episode steps:  11, steps per second: 120, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.091 [0.000, 1.000],  loss: 0.146847, mae: 3.426235, mean_q: 6.793952, mean_eps: 0.921900\n",
            "  803/9000: episode: 33, duration: 0.136s, episode steps:  16, steps per second: 118, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 0.375283, mae: 3.499464, mean_q: 6.821396, mean_eps: 0.920550\n",
            "  837/9000: episode: 34, duration: 0.284s, episode steps:  34, steps per second: 120, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 0.306944, mae: 3.598306, mean_q: 7.064600, mean_eps: 0.918050\n",
            "  850/9000: episode: 35, duration: 0.105s, episode steps:  13, steps per second: 124, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 0.238229, mae: 3.729365, mean_q: 7.349384, mean_eps: 0.915700\n",
            "  865/9000: episode: 36, duration: 0.133s, episode steps:  15, steps per second: 113, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.319615, mae: 3.720139, mean_q: 7.319443, mean_eps: 0.914300\n",
            "  893/9000: episode: 37, duration: 0.231s, episode steps:  28, steps per second: 121, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.607 [0.000, 1.000],  loss: 0.513536, mae: 3.812353, mean_q: 7.320728, mean_eps: 0.912150\n",
            "  929/9000: episode: 38, duration: 0.280s, episode steps:  36, steps per second: 128, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 0.335392, mae: 3.976550, mean_q: 7.730881, mean_eps: 0.908950\n",
            "  950/9000: episode: 39, duration: 0.175s, episode steps:  21, steps per second: 120, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 0.320973, mae: 4.063405, mean_q: 7.966753, mean_eps: 0.906100\n",
            "  968/9000: episode: 40, duration: 0.157s, episode steps:  18, steps per second: 115, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 0.385315, mae: 4.090821, mean_q: 8.054455, mean_eps: 0.904150\n",
            "  982/9000: episode: 41, duration: 0.130s, episode steps:  14, steps per second: 108, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 0.517529, mae: 4.173201, mean_q: 8.100480, mean_eps: 0.902550\n",
            " 1008/9000: episode: 42, duration: 0.193s, episode steps:  26, steps per second: 134, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 0.376229, mae: 4.264891, mean_q: 8.365219, mean_eps: 0.900550\n",
            " 1020/9000: episode: 43, duration: 0.092s, episode steps:  12, steps per second: 131, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.503408, mae: 4.313589, mean_q: 8.467445, mean_eps: 0.898650\n",
            " 1034/9000: episode: 44, duration: 0.105s, episode steps:  14, steps per second: 134, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 0.431836, mae: 4.358026, mean_q: 8.547378, mean_eps: 0.897350\n",
            " 1053/9000: episode: 45, duration: 0.150s, episode steps:  19, steps per second: 127, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.368 [0.000, 1.000],  loss: 0.480443, mae: 4.466146, mean_q: 8.801477, mean_eps: 0.895700\n",
            " 1067/9000: episode: 46, duration: 0.113s, episode steps:  14, steps per second: 124, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 0.339387, mae: 4.510337, mean_q: 8.995251, mean_eps: 0.894050\n",
            " 1091/9000: episode: 47, duration: 0.186s, episode steps:  24, steps per second: 129, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 0.497713, mae: 4.666849, mean_q: 9.195702, mean_eps: 0.892150\n",
            " 1112/9000: episode: 48, duration: 0.163s, episode steps:  21, steps per second: 129, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.602393, mae: 4.737444, mean_q: 9.368256, mean_eps: 0.889900\n",
            " 1148/9000: episode: 49, duration: 0.278s, episode steps:  36, steps per second: 129, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 0.473059, mae: 4.810606, mean_q: 9.545740, mean_eps: 0.887050\n",
            " 1165/9000: episode: 50, duration: 0.135s, episode steps:  17, steps per second: 126, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 0.656170, mae: 4.925881, mean_q: 9.651119, mean_eps: 0.884400\n",
            " 1177/9000: episode: 51, duration: 0.102s, episode steps:  12, steps per second: 118, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.473427, mae: 4.971536, mean_q: 9.723072, mean_eps: 0.882950\n",
            " 1188/9000: episode: 52, duration: 0.095s, episode steps:  11, steps per second: 116, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 0.366932, mae: 4.990510, mean_q: 9.953561, mean_eps: 0.881800\n",
            " 1242/9000: episode: 53, duration: 0.433s, episode steps:  54, steps per second: 125, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 0.615457, mae: 5.120934, mean_q: 10.052899, mean_eps: 0.878550\n",
            " 1288/9000: episode: 54, duration: 0.355s, episode steps:  46, steps per second: 129, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 0.555667, mae: 5.371989, mean_q: 10.651160, mean_eps: 0.873550\n",
            " 1300/9000: episode: 55, duration: 0.100s, episode steps:  12, steps per second: 120, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.335499, mae: 5.459308, mean_q: 10.988840, mean_eps: 0.870650\n",
            " 1318/9000: episode: 56, duration: 0.158s, episode steps:  18, steps per second: 114, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.722 [0.000, 1.000],  loss: 0.604155, mae: 5.488459, mean_q: 10.958992, mean_eps: 0.869150\n",
            " 1328/9000: episode: 57, duration: 0.087s, episode steps:  10, steps per second: 115, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 0.264066, mae: 5.639562, mean_q: 11.317328, mean_eps: 0.867750\n",
            " 1399/9000: episode: 58, duration: 0.548s, episode steps:  71, steps per second: 129, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 0.467678, mae: 5.780531, mean_q: 11.580342, mean_eps: 0.863700\n",
            " 1415/9000: episode: 59, duration: 0.122s, episode steps:  16, steps per second: 132, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 0.349326, mae: 5.888531, mean_q: 11.839335, mean_eps: 0.859350\n",
            " 1442/9000: episode: 60, duration: 0.215s, episode steps:  27, steps per second: 125, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 0.658066, mae: 6.034109, mean_q: 11.972078, mean_eps: 0.857200\n",
            " 1487/9000: episode: 61, duration: 0.351s, episode steps:  45, steps per second: 128, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 0.594374, mae: 6.214637, mean_q: 12.343918, mean_eps: 0.853600\n",
            " 1535/9000: episode: 62, duration: 0.371s, episode steps:  48, steps per second: 129, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.517406, mae: 6.341774, mean_q: 12.738317, mean_eps: 0.848950\n",
            " 1573/9000: episode: 63, duration: 0.303s, episode steps:  38, steps per second: 125, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 0.475436, mae: 6.551317, mean_q: 13.211021, mean_eps: 0.844650\n",
            " 1584/9000: episode: 64, duration: 0.095s, episode steps:  11, steps per second: 116, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 0.668643, mae: 6.624052, mean_q: 13.291064, mean_eps: 0.842200\n",
            " 1671/9000: episode: 65, duration: 0.636s, episode steps:  87, steps per second: 137, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 0.534026, mae: 6.879647, mean_q: 13.931262, mean_eps: 0.837300\n",
            " 1699/9000: episode: 66, duration: 0.193s, episode steps:  28, steps per second: 145, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.393 [0.000, 1.000],  loss: 0.527234, mae: 7.137192, mean_q: 14.447806, mean_eps: 0.831550\n",
            " 1760/9000: episode: 67, duration: 0.441s, episode steps:  61, steps per second: 138, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.574 [0.000, 1.000],  loss: 0.582941, mae: 7.392231, mean_q: 14.969227, mean_eps: 0.827100\n",
            " 1834/9000: episode: 68, duration: 0.586s, episode steps:  74, steps per second: 126, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 0.482548, mae: 7.580570, mean_q: 15.360451, mean_eps: 0.820350\n",
            " 1896/9000: episode: 69, duration: 0.503s, episode steps:  62, steps per second: 123, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 0.656598, mae: 7.910200, mean_q: 16.068115, mean_eps: 0.813550\n",
            " 1914/9000: episode: 70, duration: 0.133s, episode steps:  18, steps per second: 136, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 0.576761, mae: 8.165989, mean_q: 16.646309, mean_eps: 0.809550\n",
            " 2012/9000: episode: 71, duration: 0.701s, episode steps:  98, steps per second: 140, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 0.542339, mae: 8.479762, mean_q: 17.240520, mean_eps: 0.803750\n",
            " 2038/9000: episode: 72, duration: 0.194s, episode steps:  26, steps per second: 134, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.346 [0.000, 1.000],  loss: 0.514078, mae: 8.842217, mean_q: 18.012454, mean_eps: 0.797550\n",
            " 2055/9000: episode: 73, duration: 0.138s, episode steps:  17, steps per second: 123, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 0.375943, mae: 8.922198, mean_q: 18.272002, mean_eps: 0.795400\n",
            " 2075/9000: episode: 74, duration: 0.159s, episode steps:  20, steps per second: 126, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.773702, mae: 8.960008, mean_q: 18.271349, mean_eps: 0.793550\n",
            " 2101/9000: episode: 75, duration: 0.208s, episode steps:  26, steps per second: 125, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 0.985966, mae: 9.085498, mean_q: 18.465956, mean_eps: 0.791250\n",
            " 2149/9000: episode: 76, duration: 0.375s, episode steps:  48, steps per second: 128, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 0.988785, mae: 9.156915, mean_q: 18.657496, mean_eps: 0.787550\n",
            " 2221/9000: episode: 77, duration: 0.527s, episode steps:  72, steps per second: 137, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 0.793389, mae: 9.527621, mean_q: 19.435840, mean_eps: 0.781550\n",
            " 2254/9000: episode: 78, duration: 0.265s, episode steps:  33, steps per second: 125, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.394 [0.000, 1.000],  loss: 0.977379, mae: 9.827385, mean_q: 20.058676, mean_eps: 0.776300\n",
            " 2314/9000: episode: 79, duration: 0.476s, episode steps:  60, steps per second: 126, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.727077, mae: 9.928890, mean_q: 20.383110, mean_eps: 0.771650\n",
            " 2333/9000: episode: 80, duration: 0.139s, episode steps:  19, steps per second: 137, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 1.207895, mae: 10.080647, mean_q: 20.547570, mean_eps: 0.767700\n",
            " 2344/9000: episode: 81, duration: 0.085s, episode steps:  11, steps per second: 130, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 0.884760, mae: 10.420532, mean_q: 21.301078, mean_eps: 0.766200\n",
            " 2396/9000: episode: 82, duration: 0.380s, episode steps:  52, steps per second: 137, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 1.027695, mae: 10.372742, mean_q: 21.304695, mean_eps: 0.763050\n",
            " 2413/9000: episode: 83, duration: 0.126s, episode steps:  17, steps per second: 135, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 0.670223, mae: 10.739432, mean_q: 22.047105, mean_eps: 0.759600\n",
            " 2484/9000: episode: 84, duration: 0.489s, episode steps:  71, steps per second: 145, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 1.001306, mae: 10.909598, mean_q: 22.454325, mean_eps: 0.755200\n",
            " 2498/9000: episode: 85, duration: 0.105s, episode steps:  14, steps per second: 134, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 1.829382, mae: 11.108874, mean_q: 22.475608, mean_eps: 0.750950\n",
            " 2538/9000: episode: 86, duration: 0.304s, episode steps:  40, steps per second: 132, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 0.979916, mae: 11.206561, mean_q: 22.974243, mean_eps: 0.748250\n",
            " 2616/9000: episode: 87, duration: 0.572s, episode steps:  78, steps per second: 136, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 0.964497, mae: 11.431744, mean_q: 23.419776, mean_eps: 0.742350\n",
            " 2701/9000: episode: 88, duration: 0.618s, episode steps:  85, steps per second: 137, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 1.298498, mae: 11.999732, mean_q: 24.527031, mean_eps: 0.734200\n",
            " 2719/9000: episode: 89, duration: 0.131s, episode steps:  18, steps per second: 138, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 1.355428, mae: 12.389897, mean_q: 25.282253, mean_eps: 0.729050\n",
            " 2740/9000: episode: 90, duration: 0.154s, episode steps:  21, steps per second: 136, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 1.343656, mae: 12.494704, mean_q: 25.511139, mean_eps: 0.727100\n",
            " 2791/9000: episode: 91, duration: 0.372s, episode steps:  51, steps per second: 137, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 1.108002, mae: 12.442808, mean_q: 25.548322, mean_eps: 0.723500\n",
            " 2824/9000: episode: 92, duration: 0.242s, episode steps:  33, steps per second: 136, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 1.605261, mae: 12.629423, mean_q: 25.938785, mean_eps: 0.719300\n",
            " 2919/9000: episode: 93, duration: 0.667s, episode steps:  95, steps per second: 142, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 1.129068, mae: 13.145620, mean_q: 26.886426, mean_eps: 0.712900\n",
            " 3065/9000: episode: 94, duration: 1.024s, episode steps: 146, steps per second: 143, episode reward: 146.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 1.307083, mae: 13.702606, mean_q: 28.049325, mean_eps: 0.700850\n",
            " 3082/9000: episode: 95, duration: 0.139s, episode steps:  17, steps per second: 122, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 1.018911, mae: 14.103589, mean_q: 28.800644, mean_eps: 0.692700\n",
            " 3094/9000: episode: 96, duration: 0.096s, episode steps:  12, steps per second: 125, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 0.578689, mae: 14.193714, mean_q: 29.323449, mean_eps: 0.691250\n",
            " 3111/9000: episode: 97, duration: 0.125s, episode steps:  17, steps per second: 136, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 1.752828, mae: 14.436139, mean_q: 29.656753, mean_eps: 0.689800\n",
            " 3216/9000: episode: 98, duration: 0.734s, episode steps: 105, steps per second: 143, episode reward: 105.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 1.258812, mae: 14.620254, mean_q: 30.049574, mean_eps: 0.683700\n",
            " 3372/9000: episode: 99, duration: 1.127s, episode steps: 156, steps per second: 138, episode reward: 156.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 1.406774, mae: 15.547369, mean_q: 31.801886, mean_eps: 0.670650\n",
            " 3471/9000: episode: 100, duration: 0.755s, episode steps:  99, steps per second: 131, episode reward: 99.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 1.938498, mae: 16.340333, mean_q: 33.393324, mean_eps: 0.657900\n",
            " 3495/9000: episode: 101, duration: 0.193s, episode steps:  24, steps per second: 125, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 2.878024, mae: 16.740507, mean_q: 34.180549, mean_eps: 0.651750\n",
            " 3598/9000: episode: 102, duration: 0.782s, episode steps: 103, steps per second: 132, episode reward: 103.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 2.300614, mae: 16.639313, mean_q: 34.009885, mean_eps: 0.645400\n",
            " 3727/9000: episode: 103, duration: 0.936s, episode steps: 129, steps per second: 138, episode reward: 129.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 1.875145, mae: 17.340598, mean_q: 35.368986, mean_eps: 0.633800\n",
            " 3871/9000: episode: 104, duration: 1.040s, episode steps: 144, steps per second: 138, episode reward: 144.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 2.361114, mae: 18.043883, mean_q: 36.916674, mean_eps: 0.620150\n",
            " 3926/9000: episode: 105, duration: 0.440s, episode steps:  55, steps per second: 125, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 1.839889, mae: 18.607753, mean_q: 38.035928, mean_eps: 0.610200\n",
            " 4056/9000: episode: 106, duration: 1.012s, episode steps: 130, steps per second: 128, episode reward: 130.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 2.024190, mae: 18.985373, mean_q: 38.854820, mean_eps: 0.600950\n",
            " 4109/9000: episode: 107, duration: 0.420s, episode steps:  53, steps per second: 126, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 2.199698, mae: 19.482338, mean_q: 39.953691, mean_eps: 0.591800\n",
            " 4151/9000: episode: 108, duration: 0.330s, episode steps:  42, steps per second: 127, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 2.052058, mae: 19.788959, mean_q: 40.510065, mean_eps: 0.587050\n",
            " 4351/9000: episode: 109, duration: 1.452s, episode steps: 200, steps per second: 138, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 2.811010, mae: 20.560295, mean_q: 41.991383, mean_eps: 0.574950\n",
            " 4487/9000: episode: 110, duration: 0.942s, episode steps: 136, steps per second: 144, episode reward: 136.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 3.796279, mae: 21.250847, mean_q: 43.430128, mean_eps: 0.558150\n",
            " 4503/9000: episode: 111, duration: 0.119s, episode steps:  16, steps per second: 134, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 2.255674, mae: 22.037001, mean_q: 44.947977, mean_eps: 0.550550\n",
            " 4561/9000: episode: 112, duration: 0.408s, episode steps:  58, steps per second: 142, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 2.543129, mae: 21.722101, mean_q: 44.653337, mean_eps: 0.546850\n",
            " 4719/9000: episode: 113, duration: 1.173s, episode steps: 158, steps per second: 135, episode reward: 158.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 3.491591, mae: 22.504773, mean_q: 45.930552, mean_eps: 0.536050\n",
            " 4793/9000: episode: 114, duration: 0.563s, episode steps:  74, steps per second: 132, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.493103, mae: 23.038772, mean_q: 46.910503, mean_eps: 0.524450\n",
            " 4824/9000: episode: 115, duration: 0.243s, episode steps:  31, steps per second: 127, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.419 [0.000, 1.000],  loss: 3.790220, mae: 23.210777, mean_q: 47.566604, mean_eps: 0.519200\n",
            " 4918/9000: episode: 116, duration: 0.733s, episode steps:  94, steps per second: 128, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 4.170955, mae: 23.416973, mean_q: 47.879316, mean_eps: 0.512950\n",
            " 4992/9000: episode: 117, duration: 0.575s, episode steps:  74, steps per second: 129, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 4.145476, mae: 23.944843, mean_q: 48.792292, mean_eps: 0.504550\n",
            " 5026/9000: episode: 118, duration: 0.263s, episode steps:  34, steps per second: 129, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 2.428374, mae: 24.164475, mean_q: 49.517507, mean_eps: 0.499150\n",
            " 5042/9000: episode: 119, duration: 0.128s, episode steps:  16, steps per second: 125, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 3.246080, mae: 24.025935, mean_q: 49.547079, mean_eps: 0.496650\n",
            " 5114/9000: episode: 120, duration: 0.551s, episode steps:  72, steps per second: 131, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 3.093593, mae: 24.627429, mean_q: 50.484903, mean_eps: 0.492250\n",
            " 5172/9000: episode: 121, duration: 0.406s, episode steps:  58, steps per second: 143, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 3.268276, mae: 24.646931, mean_q: 50.439765, mean_eps: 0.485750\n",
            " 5275/9000: episode: 122, duration: 0.750s, episode steps: 103, steps per second: 137, episode reward: 103.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 4.645920, mae: 25.410505, mean_q: 51.786016, mean_eps: 0.477700\n",
            " 5424/9000: episode: 123, duration: 1.052s, episode steps: 149, steps per second: 142, episode reward: 149.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 3.653549, mae: 25.906815, mean_q: 52.785114, mean_eps: 0.465100\n",
            " 5450/9000: episode: 124, duration: 0.192s, episode steps:  26, steps per second: 136, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 6.139588, mae: 26.592692, mean_q: 54.225995, mean_eps: 0.456350\n",
            " 5478/9000: episode: 125, duration: 0.203s, episode steps:  28, steps per second: 138, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 3.167807, mae: 26.188861, mean_q: 53.310820, mean_eps: 0.453650\n",
            " 5629/9000: episode: 126, duration: 1.175s, episode steps: 151, steps per second: 129, episode reward: 151.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 4.347598, mae: 26.818576, mean_q: 54.836489, mean_eps: 0.444700\n",
            " 5805/9000: episode: 127, duration: 1.340s, episode steps: 176, steps per second: 131, episode reward: 176.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 4.178237, mae: 27.598991, mean_q: 56.370841, mean_eps: 0.428350\n",
            " 5972/9000: episode: 128, duration: 1.161s, episode steps: 167, steps per second: 144, episode reward: 167.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 4.556279, mae: 28.282358, mean_q: 57.585046, mean_eps: 0.411200\n",
            " 6042/9000: episode: 129, duration: 0.506s, episode steps:  70, steps per second: 138, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 4.544607, mae: 28.437295, mean_q: 58.364224, mean_eps: 0.399350\n",
            " 6230/9000: episode: 130, duration: 1.348s, episode steps: 188, steps per second: 139, episode reward: 188.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 4.552539, mae: 29.365365, mean_q: 59.957202, mean_eps: 0.386450\n",
            " 6364/9000: episode: 131, duration: 1.022s, episode steps: 134, steps per second: 131, episode reward: 134.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 5.574518, mae: 29.895447, mean_q: 60.936971, mean_eps: 0.370350\n",
            " 6564/9000: episode: 132, duration: 1.598s, episode steps: 200, steps per second: 125, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 5.724775, mae: 30.448618, mean_q: 62.152525, mean_eps: 0.353650\n",
            " 6764/9000: episode: 133, duration: 1.462s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 6.373934, mae: 31.165863, mean_q: 63.468209, mean_eps: 0.333650\n",
            " 6964/9000: episode: 134, duration: 1.501s, episode steps: 200, steps per second: 133, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 4.981392, mae: 31.836059, mean_q: 64.961344, mean_eps: 0.313650\n",
            " 7164/9000: episode: 135, duration: 1.479s, episode steps: 200, steps per second: 135, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 4.925962, mae: 32.788886, mean_q: 66.894108, mean_eps: 0.293650\n",
            " 7364/9000: episode: 136, duration: 1.478s, episode steps: 200, steps per second: 135, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 6.945759, mae: 33.527060, mean_q: 68.374432, mean_eps: 0.273650\n",
            " 7462/9000: episode: 137, duration: 0.743s, episode steps:  98, steps per second: 132, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 7.481930, mae: 34.092132, mean_q: 69.414458, mean_eps: 0.258750\n",
            " 7662/9000: episode: 138, duration: 1.430s, episode steps: 200, steps per second: 140, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 5.633391, mae: 34.627532, mean_q: 70.507115, mean_eps: 0.243850\n",
            " 7862/9000: episode: 139, duration: 1.499s, episode steps: 200, steps per second: 133, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.590197, mae: 35.420550, mean_q: 72.184106, mean_eps: 0.223850\n",
            " 8062/9000: episode: 140, duration: 1.515s, episode steps: 200, steps per second: 132, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 7.451679, mae: 36.238639, mean_q: 73.763072, mean_eps: 0.203850\n",
            " 8262/9000: episode: 141, duration: 1.532s, episode steps: 200, steps per second: 131, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 6.906288, mae: 36.663602, mean_q: 74.482204, mean_eps: 0.183850\n",
            " 8462/9000: episode: 142, duration: 1.482s, episode steps: 200, steps per second: 135, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 6.033825, mae: 37.366434, mean_q: 76.075939, mean_eps: 0.163850\n",
            " 8662/9000: episode: 143, duration: 1.408s, episode steps: 200, steps per second: 142, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.827579, mae: 37.947239, mean_q: 77.051977, mean_eps: 0.143850\n",
            " 8862/9000: episode: 144, duration: 1.413s, episode steps: 200, steps per second: 142, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 7.210514, mae: 38.595548, mean_q: 78.398544, mean_eps: 0.123850\n",
            "done, took 68.330 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2825e8e6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}